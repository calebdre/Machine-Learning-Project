{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "import nbimporter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/TrainData1.txt\", sep='\\t')\n",
    "labels = pd.read_csv(\"data/TrainLabel1.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3.82425408486233</th>\n",
       "      <th>1.92376196082870</th>\n",
       "      <th>1.91844974240116</th>\n",
       "      <th>2.35206669080519</th>\n",
       "      <th>3.11729781664639</th>\n",
       "      <th>3.05173505129779</th>\n",
       "      <th>3.30797713222509</th>\n",
       "      <th>3.43022183905707</th>\n",
       "      <th>3.58666718050779</th>\n",
       "      <th>3.60521774740972</th>\n",
       "      <th>...</th>\n",
       "      <th>1.83683028648888.12</th>\n",
       "      <th>1.85564028089015.11</th>\n",
       "      <th>1.14238946611884.6</th>\n",
       "      <th>2.05434488876763.5</th>\n",
       "      <th>2.80822448109616</th>\n",
       "      <th>1.78218586649202.12</th>\n",
       "      <th>2.66570291403744.1</th>\n",
       "      <th>2.46821436276855.2</th>\n",
       "      <th>2.47858092374228.4</th>\n",
       "      <th>2.30884176126132.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>...</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13422818791946309457778495933816971564560215186...</td>\n",
       "      <td>67114093959731547288892479669084857822801075932...</td>\n",
       "      <td>13422818791946309457778495933816971564560215186...</td>\n",
       "      <td>13422818791946309457778495933816971564560215186...</td>\n",
       "      <td>20134228187919464186667743900725457346840322779...</td>\n",
       "      <td>13422818791946309457778495933816971564560215186...</td>\n",
       "      <td>3.504</td>\n",
       "      <td>13422818791946309457778495933816971564560215186...</td>\n",
       "      <td>13422818791946309457778495933816971564560215186...</td>\n",
       "      <td>26845637583892618915556991867633943129120430373...</td>\n",
       "      <td>...</td>\n",
       "      <td>26845637583892618915556991867633943129120430373...</td>\n",
       "      <td>67114093959731547288892479669084857822801075932...</td>\n",
       "      <td>1.250</td>\n",
       "      <td>40268456375838928373335487801450914693680645559...</td>\n",
       "      <td>67114093959731547288892479669084857822801075932...</td>\n",
       "      <td>67114093959731547288892479669084857822801075932...</td>\n",
       "      <td>67114093959731547288892479669084857822801075932...</td>\n",
       "      <td>26845637583892618915556991867633943129120430373...</td>\n",
       "      <td>33557046979865773644446239834542428911400537966...</td>\n",
       "      <td>13422818791946309457778495933816971564560215186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11546481745700334532041446684281935174181082516...</td>\n",
       "      <td>81923192051904040180026773983385323642459353772...</td>\n",
       "      <td>11546481745700336049751518735632771830010697222...</td>\n",
       "      <td>11546481745700337567461590786983608485840311928...</td>\n",
       "      <td>14093311897214878950381315815876273286336264059...</td>\n",
       "      <td>11546481745700337567461590786983608485840311928...</td>\n",
       "      <td>0.129</td>\n",
       "      <td>11546481745700337567461590786983608485840311928...</td>\n",
       "      <td>11546481745700337567461590786983608485840311928...</td>\n",
       "      <td>16217727724465412374902982829292987442685014929...</td>\n",
       "      <td>...</td>\n",
       "      <td>16217727724465409339482838726591314131025785517...</td>\n",
       "      <td>81923192051904040180026773983385323642459353772...</td>\n",
       "      <td>0.341</td>\n",
       "      <td>19725119911506460485109985481592386033114246749...</td>\n",
       "      <td>81923192051904040180026773983385323642459353772...</td>\n",
       "      <td>81923192051904055357127494496893690200755500830...</td>\n",
       "      <td>81923192051904040180026773983385323642459353772...</td>\n",
       "      <td>16217727724465412374902982829292987442685014929...</td>\n",
       "      <td>18069338605547722241511982604358942422451091585...</td>\n",
       "      <td>11546481745700336049751518735632771830010697222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.719</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.795</td>\n",
       "      <td>2.705</td>\n",
       "      <td>2.895</td>\n",
       "      <td>3.032</td>\n",
       "      <td>2.988</td>\n",
       "      <td>3.241</td>\n",
       "      <td>3.380</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.859</td>\n",
       "      <td>2.571</td>\n",
       "      <td>1.338</td>\n",
       "      <td>2.273</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.627</td>\n",
       "      <td>1.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.821</td>\n",
       "      <td>1.621</td>\n",
       "      <td>1.702</td>\n",
       "      <td>2.291</td>\n",
       "      <td>3.262</td>\n",
       "      <td>3.253</td>\n",
       "      <td>3.430</td>\n",
       "      <td>3.446</td>\n",
       "      <td>3.551</td>\n",
       "      <td>3.602</td>\n",
       "      <td>...</td>\n",
       "      <td>1.414</td>\n",
       "      <td>1.574</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.103</td>\n",
       "      <td>2.966</td>\n",
       "      <td>1.768</td>\n",
       "      <td>2.501</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.323</td>\n",
       "      <td>1.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.855</td>\n",
       "      <td>1.966</td>\n",
       "      <td>1.895</td>\n",
       "      <td>2.447</td>\n",
       "      <td>3.369</td>\n",
       "      <td>3.378</td>\n",
       "      <td>3.528</td>\n",
       "      <td>3.500</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.640</td>\n",
       "      <td>...</td>\n",
       "      <td>1.803</td>\n",
       "      <td>1.723</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.153</td>\n",
       "      <td>3.081</td>\n",
       "      <td>1.882</td>\n",
       "      <td>2.586</td>\n",
       "      <td>1.723</td>\n",
       "      <td>2.545</td>\n",
       "      <td>2.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.894</td>\n",
       "      <td>2.177</td>\n",
       "      <td>2.097</td>\n",
       "      <td>2.619</td>\n",
       "      <td>3.466</td>\n",
       "      <td>3.478</td>\n",
       "      <td>3.579</td>\n",
       "      <td>3.564</td>\n",
       "      <td>3.661</td>\n",
       "      <td>3.679</td>\n",
       "      <td>...</td>\n",
       "      <td>2.042</td>\n",
       "      <td>1.865</td>\n",
       "      <td>1.457</td>\n",
       "      <td>2.243</td>\n",
       "      <td>3.215</td>\n",
       "      <td>2.024</td>\n",
       "      <td>2.636</td>\n",
       "      <td>2.063</td>\n",
       "      <td>2.690</td>\n",
       "      <td>2.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>3.736</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>2.652</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "      <td>10000000000000000887529745682247582063159023622...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        3.82425408486233  \\\n",
       "count                                            149.000   \n",
       "mean  13422818791946309457778495933816971564560215186...   \n",
       "std   11546481745700334532041446684281935174181082516...   \n",
       "min                                                3.719   \n",
       "25%                                                3.821   \n",
       "50%                                                3.855   \n",
       "75%                                                3.894   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                        1.92376196082870  \\\n",
       "count                                            149.000   \n",
       "mean  67114093959731547288892479669084857822801075932...   \n",
       "std   81923192051904040180026773983385323642459353772...   \n",
       "min                                                1.000   \n",
       "25%                                                1.621   \n",
       "50%                                                1.966   \n",
       "75%                                                2.177   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                        1.91844974240116  \\\n",
       "count                                            149.000   \n",
       "mean  13422818791946309457778495933816971564560215186...   \n",
       "std   11546481745700336049751518735632771830010697222...   \n",
       "min                                                1.000   \n",
       "25%                                                1.702   \n",
       "50%                                                1.895   \n",
       "75%                                                2.097   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                        2.35206669080519  \\\n",
       "count                                            149.000   \n",
       "mean  13422818791946309457778495933816971564560215186...   \n",
       "std   11546481745700337567461590786983608485840311928...   \n",
       "min                                                1.795   \n",
       "25%                                                2.291   \n",
       "50%                                                2.447   \n",
       "75%                                                2.619   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                        3.11729781664639  \\\n",
       "count                                            149.000   \n",
       "mean  20134228187919464186667743900725457346840322779...   \n",
       "std   14093311897214878950381315815876273286336264059...   \n",
       "min                                                2.705   \n",
       "25%                                                3.262   \n",
       "50%                                                3.369   \n",
       "75%                                                3.466   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                        3.05173505129779  3.30797713222509  \\\n",
       "count                                            149.000           149.000   \n",
       "mean  13422818791946309457778495933816971564560215186...             3.504   \n",
       "std   11546481745700337567461590786983608485840311928...             0.129   \n",
       "min                                                2.895             3.032   \n",
       "25%                                                3.253             3.430   \n",
       "50%                                                3.378             3.528   \n",
       "75%                                                3.478             3.579   \n",
       "max   10000000000000000887529745682247582063159023622...             3.736   \n",
       "\n",
       "                                        3.43022183905707  \\\n",
       "count                                            149.000   \n",
       "mean  13422818791946309457778495933816971564560215186...   \n",
       "std   11546481745700337567461590786983608485840311928...   \n",
       "min                                                2.988   \n",
       "25%                                                3.446   \n",
       "50%                                                3.500   \n",
       "75%                                                3.564   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                        3.58666718050779  \\\n",
       "count                                            149.000   \n",
       "mean  13422818791946309457778495933816971564560215186...   \n",
       "std   11546481745700337567461590786983608485840311928...   \n",
       "min                                                3.241   \n",
       "25%                                                3.551   \n",
       "50%                                                3.617   \n",
       "75%                                                3.661   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                        3.60521774740972  \\\n",
       "count                                            149.000   \n",
       "mean  26845637583892618915556991867633943129120430373...   \n",
       "std   16217727724465412374902982829292987442685014929...   \n",
       "min                                                3.380   \n",
       "25%                                                3.602   \n",
       "50%                                                3.640   \n",
       "75%                                                3.679   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                             ...                          \\\n",
       "count                        ...                           \n",
       "mean                         ...                           \n",
       "std                          ...                           \n",
       "min                          ...                           \n",
       "25%                          ...                           \n",
       "50%                          ...                           \n",
       "75%                          ...                           \n",
       "max                          ...                           \n",
       "\n",
       "                                     1.83683028648888.12  \\\n",
       "count                                            149.000   \n",
       "mean  26845637583892618915556991867633943129120430373...   \n",
       "std   16217727724465409339482838726591314131025785517...   \n",
       "min                                                1.000   \n",
       "25%                                                1.414   \n",
       "50%                                                1.803   \n",
       "75%                                                2.042   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                     1.85564028089015.11  1.14238946611884.6  \\\n",
       "count                                            149.000             149.000   \n",
       "mean  67114093959731547288892479669084857822801075932...               1.250   \n",
       "std   81923192051904040180026773983385323642459353772...               0.341   \n",
       "min                                                1.000               1.000   \n",
       "25%                                                1.574               1.000   \n",
       "50%                                                1.723               1.000   \n",
       "75%                                                1.865               1.457   \n",
       "max   10000000000000000887529745682247582063159023622...               2.652   \n",
       "\n",
       "                                      2.05434488876763.5  \\\n",
       "count                                            149.000   \n",
       "mean  40268456375838928373335487801450914693680645559...   \n",
       "std   19725119911506460485109985481592386033114246749...   \n",
       "min                                                1.859   \n",
       "25%                                                2.103   \n",
       "50%                                                2.153   \n",
       "75%                                                2.243   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                        2.80822448109616  \\\n",
       "count                                            149.000   \n",
       "mean  67114093959731547288892479669084857822801075932...   \n",
       "std   81923192051904040180026773983385323642459353772...   \n",
       "min                                                2.571   \n",
       "25%                                                2.966   \n",
       "50%                                                3.081   \n",
       "75%                                                3.215   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                     1.78218586649202.12  \\\n",
       "count                                            149.000   \n",
       "mean  67114093959731547288892479669084857822801075932...   \n",
       "std   81923192051904055357127494496893690200755500830...   \n",
       "min                                                1.338   \n",
       "25%                                                1.768   \n",
       "50%                                                1.882   \n",
       "75%                                                2.024   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                      2.66570291403744.1  \\\n",
       "count                                            149.000   \n",
       "mean  67114093959731547288892479669084857822801075932...   \n",
       "std   81923192051904040180026773983385323642459353772...   \n",
       "min                                                2.273   \n",
       "25%                                                2.501   \n",
       "50%                                                2.586   \n",
       "75%                                                2.636   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                      2.46821436276855.2  \\\n",
       "count                                            149.000   \n",
       "mean  26845637583892618915556991867633943129120430373...   \n",
       "std   16217727724465412374902982829292987442685014929...   \n",
       "min                                                1.000   \n",
       "25%                                                1.000   \n",
       "50%                                                1.723   \n",
       "75%                                                2.063   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                      2.47858092374228.4  \\\n",
       "count                                            149.000   \n",
       "mean  33557046979865773644446239834542428911400537966...   \n",
       "std   18069338605547722241511982604358942422451091585...   \n",
       "min                                                1.627   \n",
       "25%                                                2.323   \n",
       "50%                                                2.545   \n",
       "75%                                                2.690   \n",
       "max   10000000000000000887529745682247582063159023622...   \n",
       "\n",
       "                                      2.30884176126132.4  \n",
       "count                                            149.000  \n",
       "mean  13422818791946309457778495933816971564560215186...  \n",
       "std   11546481745700336049751518735632771830010697222...  \n",
       "min                                                1.195  \n",
       "25%                                                1.945  \n",
       "50%                                                2.094  \n",
       "75%                                                2.225  \n",
       "max   10000000000000000887529745682247582063159023622...  \n",
       "\n",
       "[8 rows x 3312 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1\n",
       "count 149.000\n",
       "mean    1.604\n",
       "std     1.096\n",
       "min     1.000\n",
       "25%     1.000\n",
       "50%     1.000\n",
       "75%     2.000\n",
       "max     5.000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "#### Todos:\n",
    "+ figure out how many and which rows for each column have these huge numbers\n",
    "+ figure out a way to map the values to ones that fit more with the data \n",
    "    * make them \"average joes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                               69.000\n",
       "mean    10000000000000002101697803323328251387822715387...\n",
       "std     12230631806435245486489244355180364340614809249...\n",
       "min     10000000000000000887529745682247582063159023622...\n",
       "25%     10000000000000000887529745682247582063159023622...\n",
       "50%     10000000000000000887529745682247582063159023622...\n",
       "75%     10000000000000000887529745682247582063159023622...\n",
       "max     10000000000000000887529745682247582063159023622...\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr = train.iloc[0,:] # first row\n",
    "poten_errors = fr[fr > fr.mean()]\n",
    "poten_errors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   3243.000\n",
       "mean       2.167\n",
       "std        0.553\n",
       "min        1.000\n",
       "25%        1.884\n",
       "50%        2.194\n",
       "75%        2.482\n",
       "max        3.904\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr[~(fr > fr.mean())].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 69 rows with vastly diffrent values. We can't just drop the rows or columns because the signal to noise ratio for both axis is really low. Lets find out more about these errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10ffbfc50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1109a62e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poten_errors.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like all the error numbers are the same even though the standard deviation, mean, and max are different numbers. Let's verify that the numbers are actually the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max - Min\n",
      " 0.0 \n",
      "Max - All\n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "mMax = poten_errors.max()\n",
    "all_diffs = [mMax - i for i in poten_errors]\n",
    "extreme_diffs = poten_errors.max() - poten_errors.min()\n",
    "\n",
    "print(\"Max - Min\\n\", extreme_diffs, \"\\nMax - All\\n\", all_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the errors are indeed the same number, lets replace all of them with the mean of the particular column that they're in for now. We can think of a better way to replace those values later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    train_col = train[col]\n",
    "    gt_mean = train_col > train_col.mean()\n",
    "    new_col_mean = train_col[~gt_mean].mean()\n",
    "    \n",
    "    train[col][gt_mean] = new_col_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3.82425408486233</th>\n",
       "      <th>1.92376196082870</th>\n",
       "      <th>1.91844974240116</th>\n",
       "      <th>2.35206669080519</th>\n",
       "      <th>3.11729781664639</th>\n",
       "      <th>3.05173505129779</th>\n",
       "      <th>3.30797713222509</th>\n",
       "      <th>3.43022183905707</th>\n",
       "      <th>3.58666718050779</th>\n",
       "      <th>3.60521774740972</th>\n",
       "      <th>...</th>\n",
       "      <th>1.83683028648888.12</th>\n",
       "      <th>1.85564028089015.11</th>\n",
       "      <th>1.14238946611884.6</th>\n",
       "      <th>2.05434488876763.5</th>\n",
       "      <th>2.80822448109616</th>\n",
       "      <th>1.78218586649202.12</th>\n",
       "      <th>2.66570291403744.1</th>\n",
       "      <th>2.46821436276855.2</th>\n",
       "      <th>2.47858092374228.4</th>\n",
       "      <th>2.30884176126132.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>...</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.854</td>\n",
       "      <td>1.889</td>\n",
       "      <td>1.878</td>\n",
       "      <td>2.449</td>\n",
       "      <td>3.348</td>\n",
       "      <td>3.356</td>\n",
       "      <td>3.386</td>\n",
       "      <td>3.480</td>\n",
       "      <td>3.593</td>\n",
       "      <td>3.633</td>\n",
       "      <td>...</td>\n",
       "      <td>1.683</td>\n",
       "      <td>1.729</td>\n",
       "      <td>1.031</td>\n",
       "      <td>2.161</td>\n",
       "      <td>3.083</td>\n",
       "      <td>1.889</td>\n",
       "      <td>2.574</td>\n",
       "      <td>1.620</td>\n",
       "      <td>2.483</td>\n",
       "      <td>2.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.719</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.795</td>\n",
       "      <td>2.705</td>\n",
       "      <td>2.895</td>\n",
       "      <td>3.032</td>\n",
       "      <td>2.988</td>\n",
       "      <td>3.241</td>\n",
       "      <td>3.380</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.859</td>\n",
       "      <td>2.571</td>\n",
       "      <td>1.338</td>\n",
       "      <td>2.273</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.627</td>\n",
       "      <td>1.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.821</td>\n",
       "      <td>1.621</td>\n",
       "      <td>1.702</td>\n",
       "      <td>2.291</td>\n",
       "      <td>3.262</td>\n",
       "      <td>3.253</td>\n",
       "      <td>3.386</td>\n",
       "      <td>3.446</td>\n",
       "      <td>3.551</td>\n",
       "      <td>3.602</td>\n",
       "      <td>...</td>\n",
       "      <td>1.414</td>\n",
       "      <td>1.574</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.103</td>\n",
       "      <td>2.966</td>\n",
       "      <td>1.768</td>\n",
       "      <td>2.501</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.323</td>\n",
       "      <td>1.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.854</td>\n",
       "      <td>1.949</td>\n",
       "      <td>1.887</td>\n",
       "      <td>2.447</td>\n",
       "      <td>3.363</td>\n",
       "      <td>3.372</td>\n",
       "      <td>3.386</td>\n",
       "      <td>3.498</td>\n",
       "      <td>3.608</td>\n",
       "      <td>3.638</td>\n",
       "      <td>...</td>\n",
       "      <td>1.763</td>\n",
       "      <td>1.723</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.153</td>\n",
       "      <td>3.081</td>\n",
       "      <td>1.882</td>\n",
       "      <td>2.585</td>\n",
       "      <td>1.673</td>\n",
       "      <td>2.539</td>\n",
       "      <td>2.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.887</td>\n",
       "      <td>2.172</td>\n",
       "      <td>2.092</td>\n",
       "      <td>2.599</td>\n",
       "      <td>3.457</td>\n",
       "      <td>3.466</td>\n",
       "      <td>3.395</td>\n",
       "      <td>3.559</td>\n",
       "      <td>3.658</td>\n",
       "      <td>3.677</td>\n",
       "      <td>...</td>\n",
       "      <td>2.027</td>\n",
       "      <td>1.862</td>\n",
       "      <td>1.031</td>\n",
       "      <td>2.218</td>\n",
       "      <td>3.212</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.636</td>\n",
       "      <td>2.053</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.973</td>\n",
       "      <td>2.695</td>\n",
       "      <td>2.619</td>\n",
       "      <td>2.966</td>\n",
       "      <td>3.720</td>\n",
       "      <td>3.722</td>\n",
       "      <td>3.502</td>\n",
       "      <td>3.689</td>\n",
       "      <td>3.742</td>\n",
       "      <td>3.743</td>\n",
       "      <td>...</td>\n",
       "      <td>2.321</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1.246</td>\n",
       "      <td>2.512</td>\n",
       "      <td>3.527</td>\n",
       "      <td>2.724</td>\n",
       "      <td>2.800</td>\n",
       "      <td>2.903</td>\n",
       "      <td>3.084</td>\n",
       "      <td>2.576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       3.82425408486233  1.92376196082870  1.91844974240116  2.35206669080519  \\\n",
       "count           149.000           149.000           149.000           149.000   \n",
       "mean              3.854             1.889             1.878             2.449   \n",
       "std               0.048             0.392             0.304             0.227   \n",
       "min               3.719             1.000             1.000             1.795   \n",
       "25%               3.821             1.621             1.702             2.291   \n",
       "50%               3.854             1.949             1.887             2.447   \n",
       "75%               3.887             2.172             2.092             2.599   \n",
       "max               3.973             2.695             2.619             2.966   \n",
       "\n",
       "       3.11729781664639  3.05173505129779  3.30797713222509  3.43022183905707  \\\n",
       "count           149.000           149.000           149.000           149.000   \n",
       "mean              3.348             3.356             3.386             3.480   \n",
       "std               0.178             0.175             0.063             0.120   \n",
       "min               2.705             2.895             3.032             2.988   \n",
       "25%               3.262             3.253             3.386             3.446   \n",
       "50%               3.363             3.372             3.386             3.498   \n",
       "75%               3.457             3.466             3.395             3.559   \n",
       "max               3.720             3.722             3.502             3.689   \n",
       "\n",
       "       3.58666718050779  3.60521774740972         ...          \\\n",
       "count           149.000           149.000         ...           \n",
       "mean              3.593             3.633         ...           \n",
       "std               0.092             0.061         ...           \n",
       "min               3.241             3.380         ...           \n",
       "25%               3.551             3.602         ...           \n",
       "50%               3.608             3.638         ...           \n",
       "75%               3.658             3.677         ...           \n",
       "max               3.742             3.743         ...           \n",
       "\n",
       "       1.83683028648888.12  1.85564028089015.11  1.14238946611884.6  \\\n",
       "count              149.000              149.000             149.000   \n",
       "mean                 1.683                1.729               1.031   \n",
       "std                  0.418                0.265               0.058   \n",
       "min                  1.000                1.000               1.000   \n",
       "25%                  1.414                1.574               1.000   \n",
       "50%                  1.763                1.723               1.000   \n",
       "75%                  2.027                1.862               1.031   \n",
       "max                  2.321                2.625               1.246   \n",
       "\n",
       "       2.05434488876763.5  2.80822448109616  1.78218586649202.12  \\\n",
       "count             149.000           149.000              149.000   \n",
       "mean                2.161             3.083                1.889   \n",
       "std                 0.111             0.197                0.231   \n",
       "min                 1.859             2.571                1.338   \n",
       "25%                 2.103             2.966                1.768   \n",
       "50%                 2.153             3.081                1.882   \n",
       "75%                 2.218             3.212                2.021   \n",
       "max                 2.512             3.527                2.724   \n",
       "\n",
       "       2.66570291403744.1  2.46821436276855.2  2.47858092374228.4  \\\n",
       "count             149.000             149.000             149.000   \n",
       "mean                2.574               1.620               2.483   \n",
       "std                 0.107               0.524               0.284   \n",
       "min                 2.273               1.000               1.627   \n",
       "25%                 2.501               1.000               2.323   \n",
       "50%                 2.585               1.673               2.539   \n",
       "75%                 2.636               2.053               2.669   \n",
       "max                 2.800               2.903               3.084   \n",
       "\n",
       "       2.30884176126132.4  \n",
       "count             149.000  \n",
       "mean                2.060  \n",
       "std                 0.231  \n",
       "min                 1.195  \n",
       "25%                 1.945  \n",
       "50%                 2.093  \n",
       "75%                 2.217  \n",
       "max                 2.576  \n",
       "\n",
       "[8 rows x 3312 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out how correlated each of these variabels are with the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(labels, train):\n",
    "    n = len(labels)\n",
    "    v1, v2 = labels.values, train.values\n",
    "    sums = np.multiply.outer(v2.sum(0), v1.sum(0))\n",
    "    stds = np.multiply.outer(v2.std(0), v1.std(0))\n",
    "    return pd.DataFrame((v2.T.dot(v1) - sums / n) / stds / n, train.columns, labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_corr = corr(labels, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_corrs(correlation_result, with_labels=True):\n",
    "    if with_labels:\n",
    "        return [(i, correlation_result[correlation_result > i].dropna().size) for i in np.arange(0,1.1,.1)]\n",
    "    else:\n",
    "        return [correlation_result[correlation_result > i].dropna().size for i in np.arange(0,1.1,.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 1907),\n",
       " (0.1, 1459),\n",
       " (0.2, 1090),\n",
       " (0.30000000000000004, 687),\n",
       " (0.4, 369),\n",
       " (0.5, 161),\n",
       " (0.6000000000000001, 37),\n",
       " (0.7000000000000001, 4),\n",
       " (0.8, 0),\n",
       " (0.9, 0),\n",
       " (1.0, 0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_corrs(train_label_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are lots of columns that aren't at all correlated with the labels. Let's drop all the ones who have a 20% or lower correlation. \n",
    "\n",
    "*idea: to improve the model, we could look into using the 20% category and play with corrlated columns in that category.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train_label_corr[train_label_corr >= .3].dropna().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have so many columns. For now, it's fine but we could use PCA to reduce the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html\n",
    "# https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/\n",
    "# https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues\n",
    "train_corrs = train.corr()\n",
    "correlation_threshold = .85\n",
    "# threshold for dropping correlated columns\n",
    "high_corrs = {}\n",
    "for col in train_corrs:\n",
    "    df = train_corrs[col]\n",
    "    corrs = df[df >= correlation_threshold].dropna().keys().drop(col)\n",
    "    if corrs.size > 0:\n",
    "        high_corrs[col] = corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
       "       ...\n",
       "       'f677', 'f678', 'f679', 'f680', 'f681', 'f682', 'f683', 'f684', 'f685',\n",
       "       'f686'],\n",
       "      dtype='object', length=687)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label_map = {}\n",
    "for i, col in enumerate(train.columns):\n",
    "    new_label_map[col] = \"f{}\".format(i)\n",
    "\n",
    "train = train.rename(columns=new_label_map)\n",
    "\n",
    "labels = labels.rename(columns={\"1\": \"label\"})\n",
    "merged = labels.merge(train, left_index=True,right_index=True)\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "- Are there a lot of outliers? If so, how many?\n",
    "- What is the relationship between each of the variables and the label? Linear? Parabolic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation is really good. Lets find outliers by getting the values that are `mean + std*n, n= {2 to 5}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_low_high = lambda mean, std, i: (df.mean() + (df.std()*float(i)), df.mean() + (df.std()*float(i+1)))\n",
    "\n",
    "v = {}\n",
    "for col in train:\n",
    "    df = train[col]\n",
    "    f = []\n",
    "    stds_from_min = np.floor((df.min() - df.mean()) / df.std())\n",
    "    for i in range(int(stds_from_min), 0):\n",
    "        low, high = calc_low_high(df.mean(), df.std(), i)\n",
    "        num_in_range = df[(low < df) & (df < high)].size\n",
    "        f.append((i, num_in_range))\n",
    "    \n",
    "    stds_from_max = (df.max() - df.mean()) / df.std()\n",
    "    for i in range(int(np.ceil(stds_from_max))):\n",
    "        low, high = calc_low_high(df.mean(), df.std(), i)\n",
    "        num_in_range = df[(low < df) & (df < high)].size\n",
    "        f.append((i, num_in_range))\n",
    "    v[col] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in train.columns:\n",
    "#     train[col].plot.kde()\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dist = {}\n",
    "for key in v:\n",
    "    data = v[key]\n",
    "    for item in data:\n",
    "        if item[0] not in std_dist:\n",
    "            std_dist[item[0]] = [item[1]]\n",
    "        else:\n",
    "            std_dist[item[0]].append(item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows, for each column in the training set, the number of values that fall into categories corresponding to the number of standard deveiations from the mean. \n",
    "The keys are the stds from mean and the values are the number of values that are that many stds from the mean found in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# for category in std_dist:\n",
    "#     plt.hist(std_dist[category], label=str(category))\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It actually seems like there's not a whole lot of values that are super far away from the mean in terms of stds. If there were, we'd think about how to replace them or remove records (although removing would be a bad choice because we only have 149 records to start with)\n",
    "\n",
    "Let's find out the relationship between the labels and each of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouped = merged.groupby(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_grouped.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "## Which algorithm to use?\n",
    "We'll use a random forest classifier (rfc) with bootstrapping and feature bagging optimizations because:\n",
    "- ease of implementation\n",
    "- rfcs handle multi-class predictions well without more additional effort\n",
    "- works well with high dimensional data\n",
    "- we'll choose use random forest as opposed to boosted trees since we have highly dimensional data\n",
    "- with a reasonably high probability, can be used with the other datasets for this project since the algorithm is very robust\n",
    "\n",
    "## The Algorithm\n",
    "We'll use the CART algorithm for splitting since we have continuous data.  \n",
    "  \n",
    "[Full example](https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/)  \n",
    "  \n",
    "Steps:\n",
    "1. Initialize Tree\n",
    "2. For each column, calc best split across all rows based using gini impurity score - [exmplanation](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) | [exmaple](https://www.researchgate.net/post/How_to_compute_impurity_using_Gini_Index) | [useful blog](http://dni-institute.in/blogs/cart-algorithm-for-decision-tree/)\n",
    "3. Split the dataset based on the split condition with the highest gini score and add both sets as leaves on a tree node. The node represents a decision point, that being the condition with the highest gini score.\n",
    "3. Repeat 2 & 3 until an arbitrary minimum number of rows are left\n",
    "4. Prune tree\n",
    "\n",
    "ideas:\n",
    "- instead of using the raw values, categorize the numbers as # of stds away from mean\n",
    "- > Alternatively, the random forest can apply weight concept for considering the impact of result from any decision tree. Tree with high error rate are given low weight value and vise versa. This would increase the decision impact of trees with low error rate - [medium post](https://medium.com/machine-learning-101/chapter-5-random-forest-classifier-56dc7425c3e1)\n",
    "- [parameters to  tune](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = train[train[\"f1\"] > 2.5].merge(labels, left_index=True, right_index=True).groupby(\"label\")\n",
    "\n",
    "# print(( 1 - (g.count()/149)**2).sum(axis=0))\n",
    "# print(((g.count()/149) ** 2 )[\"f1\"].sum())\n",
    "# 1 - ((g.size() / 149) ** 2).sum()\n",
    "# (g.count() / 149) ** 2\n",
    "# (1 - np.sum((g.count() / 149) ** 2)) * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_best_gini_split(df, labels):\n",
    "    total_rows = df.shape[0]\n",
    "    \n",
    "    def calc(col_df):\n",
    "        print(col_df.name)\n",
    "        min_cost = 2\n",
    "        min_cost_index = -1\n",
    "        for index, row in col_df.iteritems():\n",
    "            split1 = col_df[row > col_df]\n",
    "            split2 = col_df[row < col_df]\n",
    "\n",
    "            s1_grouped = labels.merge(pd.DataFrame(split1), left_index=True, right_index=True).groupby(\"label\")\n",
    "            s2_grouped = labels.merge(pd.DataFrame(split2), left_index=True, right_index=True).groupby(\"label\")\n",
    "\n",
    "            s1_group_count = s1_grouped.count()\n",
    "            s2_group_count = s2_grouped.count()\n",
    "            \n",
    "            s1_cost = (1 - np.power(s1_group_count / s1_group_count.sum(), 2).sum(axis=0)) * (split1.shape[0] / total_rows)\n",
    "            s2_cost = (1 - np.power(s2_group_count / s2_group_count.sum(), 2).sum(axis=0)) * (split2.shape[0] / total_rows)\n",
    "\n",
    "            total_cost = (s1_cost + s2_cost).iloc[0]\n",
    "            if total_cost < min_cost:\n",
    "                min_cost =total_cost\n",
    "                min_cost_index = index\n",
    "        return pd.Series({\"cost\": min_cost, \"index\": min_cost_index})\n",
    "    \n",
    "    splits = df.apply(calc, axis=0)\n",
    "    best_split_col = splits.T[\"cost\"].idxmin()\n",
    "    best_split_index = splits[best_split_col][\"index\"]\n",
    "    \n",
    "    return best_split_col, df[best_split_col][best_split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = calc_best_gini_split(train[[\"f1\", \"f0\"]], labels)\n",
    "# g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trees(df, labels, trees=10, num_features=None, min_samples_for_split=8):\n",
    "    if num_features is None:\n",
    "        num_features = np.floor(np.sqrt(df.columns.size))\n",
    "    trees = []\n",
    "    for i in range(max_trees):\n",
    "        features = np.random.choice(df.columns, size=num_features, replace=False)\n",
    "        df = df[features]\n",
    "        tree = {}\n",
    "        while df.shape[0] >= min_samples_for_split:\n",
    "            col, val = calc_best_gini_split(df, labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
