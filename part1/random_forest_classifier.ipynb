{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "from math import sqrt, floor\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import pandas as pd\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "train = pd.read_csv(\"cleaned_testData1.csv\")\n",
    "labels = pd.read_csv(\"cleaned_trainLabel1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train.columns[0], axis=1)\n",
    "labels = labels.drop(labels.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df, labels):\n",
    "    return labels.merge(df, left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mprint(*args):\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "# Model Building\n",
    "\n",
    "## Which algorithm to use?\n",
    "We'll use a **random forest classifier** (rfc) with bootstrapping and feature bagging optimizations because:\n",
    "- ease of implementation\n",
    "- rfcs handle multi-class predictions well without more additional effort\n",
    "- works well with high dimensional data\n",
    "- we'll choose use random forest as opposed to boosted trees since we have highly dimensional data\n",
    "- with a reasonably high probability, can be used with the other datasets for this project since the algorithm is very robust\n",
    "\n",
    "## The Algorithm\n",
    "We'll use the CART algorithm for splitting since we have continuous data.  \n",
    "  \n",
    "[Full example](https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/)  \n",
    "  \n",
    "Steps:\n",
    "1. Initialize Tree\n",
    "2. For each column, calc best split across all rows based using gini impurity score - [exmplanation](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) | [exmaple](https://www.researchgate.net/post/How_to_compute_impurity_using_Gini_Index) | [useful blog](http://dni-institute.in/blogs/cart-algorithm-for-decision-tree/)\n",
    "3. Split the dataset based on the split condition with the highest gini score and add both sets as leaves on a tree node. The node represents a decision point, that being the condition with the highest gini score.\n",
    "3. Repeat 2 & 3 until an arbitrary minimum number of rows are left\n",
    "4. Prune tree\n",
    "\n",
    "ideas:\n",
    "- instead of using the raw values, categorize the numbers as # of stds away from mean\n",
    "- > Alternatively, the random forest can apply weight concept for considering the impact of result from any decision tree. Tree with high error rate are given low weight value and vise versa. This would increase the decision impact of trees with low error rate - [medium post](https://medium.com/machine-learning-101/chapter-5-random-forest-classifier-56dc7425c3e1)\n",
    "- [parameters to  tune](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n",
    "- https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "- https://stats.stackexchange.com/questions/260460/optimization-of-a-random-forest-model\n",
    "- https://followthedata.wordpress.com/2012/06/02/practical-advice-for-machine-learning-bias-variance/\n",
    "- https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST\n",
    "# def calc_best_gini_split(df, labels):\n",
    "#     total_rows = df.shape[0]\n",
    "    \n",
    "#     def calc(col_df):\n",
    "#         def g(item):\n",
    "#             split1 = col_df[item > col_df]\n",
    "#             split2 = col_df[item < col_df]\n",
    "            \n",
    "#             s1_grouped = labels.merge(pd.DataFrame(split1), left_index=True, right_index=True).groupby(\"label\")\n",
    "#             s2_grouped = labels.merge(pd.DataFrame(split2), left_index=True, right_index=True).groupby(\"label\")\n",
    "            \n",
    "#             s1_group_count = s1_grouped.count()\n",
    "#             s2_group_count = s2_grouped.count()\n",
    "            \n",
    "#             s1_cost = (1 - np.power(s1_group_count / s1_group_count.sum(), 2).sum(axis=0)) * (split1.shape[0] / total_rows)\n",
    "#             s2_cost = (1 - np.power(s2_group_count / s2_group_count.sum(), 2).sum(axis=0)) * (split2.shape[0] / total_rows)\n",
    "\n",
    "#             return (s1_cost + s2_cost).iloc[0]\n",
    "        \n",
    "#         # minimum cost for particular columns        \n",
    "#         costs = col_df.apply(g)\n",
    "#         min_cost = costs.min()\n",
    "#         print(costs.shape, costs.idxmin(), costs, df)\n",
    "#         min_cost_val = costs.iloc[costs.idxmin()]\n",
    "        \n",
    "#         return pd.Series({\"cost\": min_cost, \"column\": col_df.name, \"val\": min_cost_val})\n",
    "    \n",
    "#     splits = df.apply(calc, axis=0)\n",
    "    \n",
    "#     # minimum cost for whole set\n",
    "#     transposed = splits.T\n",
    "#     transposed[\"cost\"] = transposed[\"cost\"].astype(np.float32)\n",
    "#     best_split = splits[transposed[\"cost\"].idxmin()]\n",
    "    \n",
    "#     return best_split[\"column\"], best_split[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = time()\n",
    "# calc_best_gini_split(train.iloc[:, 0:70], labels)\n",
    "# time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_best_gini_split(df, labels):\n",
    "    total_rows = df.shape[0]\n",
    "    \n",
    "    def calc(col_df):\n",
    "        min_cost = 2\n",
    "        min_cost_index = -1\n",
    "        for index, row in col_df.iteritems():\n",
    "            split1 = col_df[row > col_df]\n",
    "            split2 = col_df[row < col_df]\n",
    "\n",
    "            s1_grouped = labels.merge(pd.DataFrame(split1), left_index=True, right_index=True).groupby(\"label\")\n",
    "            s2_grouped = labels.merge(pd.DataFrame(split2), left_index=True, right_index=True).groupby(\"label\")\n",
    "\n",
    "            s1_group_count = s1_grouped.count()\n",
    "            s2_group_count = s2_grouped.count()\n",
    "            \n",
    "            s1_cost = (1 - np.power(s1_group_count / s1_group_count.sum(), 2).sum(axis=0)) * (split1.shape[0] / total_rows)\n",
    "            s2_cost = (1 - np.power(s2_group_count / s2_group_count.sum(), 2).sum(axis=0)) * (split2.shape[0] / total_rows)\n",
    "\n",
    "            total_cost = (s1_cost + s2_cost).iloc[0]\n",
    "            if total_cost < min_cost:\n",
    "                min_cost = total_cost\n",
    "                min_cost_index = index\n",
    "        return pd.Series({\"cost\": min_cost, \"index\": min_cost_index})\n",
    "    \n",
    "    splits = df.apply(calc, axis=0)\n",
    "    best_split_col = splits.T[\"cost\"].idxmin()\n",
    "    best_split_index = splits[best_split_col][\"index\"]\n",
    "    \n",
    "    return best_split_col, df[best_split_col][best_split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = time()\n",
    "# calc_best_gini_split(train.iloc[:, 0:70], labels)\n",
    "# time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, column, value):\n",
    "        self.col = column\n",
    "        self.val = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def traverse(self, row):\n",
    "        if row[self.col] > self.val:\n",
    "            return self.left\n",
    "        else:\n",
    "            return self.right\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "    \n",
    "    def grow(self, origin_df, labels, max_depth = 20, min_split_samples = 10):\n",
    "        def classify_branch(df, labels):\n",
    "            return labels.merge(df, left_index=True, right_index=True).groupby(\"label\").count().sum(axis=1).idxmax()\n",
    "        \n",
    "        def grow_recurse(df, labels, depth):\n",
    "            print(\"parsing @ depth {}\".format(depth))\n",
    "            col, val = calc_best_gini_split(df, labels)\n",
    "            left_split = df[df[col] > val]\n",
    "            right_split = df[df[col] < val]\n",
    "\n",
    "            if depth > max_depth or np.minimum(left_split.shape[0], right_split.shape[0]) < min_split_samples:\n",
    "                classification = classify_branch(df, labels)\n",
    "                print(\"classified {} at depth {} to be in class {}\".format(col, depth, classification))\n",
    "                return classification\n",
    "\n",
    "            node = Node(col, val)\n",
    "            node.left = grow_recurse(left_split, labels, depth + 1)\n",
    "            node.right = grow_recurse(right_split, labels, depth + 1)\n",
    "\n",
    "            print(\"Done with depth {}\".format(depth))\n",
    "            return node\n",
    "        \n",
    "        self.root = grow_recurse(origin_df, labels, 1)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, row):\n",
    "        if self.root is None: \n",
    "            raise Exception(\"Must call `grow` before using `predict`\")\n",
    "        \n",
    "        node = self.root\n",
    "        while type(node) is not np.int64:\n",
    "            node = self.root.traverse(row)\n",
    "        \n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_row = -5\n",
    "# t = train.iloc[:, 0:15]\n",
    "\n",
    "# DecisionTree().grow(t, labels).predict(t.iloc[test_row]), labels.iloc[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self):\n",
    "        self.trees = []\n",
    "    \n",
    "    def grow(self, origin_df, labels, num_trees=10, num_features=None, num_sample_rows=None , max_tree_depth=20, min_split_samples=5):\n",
    "        if num_features is None:\n",
    "            num_features = floor(sqrt(origin_df.columns.size))\n",
    "        if num_sample_rows is None:\n",
    "            num_sample_rows = floor(origin_df.shape[0] / 4)\n",
    "\n",
    "        for i in range(num_trees):\n",
    "            features = np.random.choice(origin_df.columns, size=num_features, replace=False)\n",
    "            rows = np.random.choice(origin_df.shape[0], size=num_sample_rows, replace=False)\n",
    "\n",
    "            df = origin_df[features]\n",
    "            df = df.iloc[rows]\n",
    "\n",
    "            print(\"\\n*** Creating tree #{} ***\\n\".format(i+1))\n",
    "            self.trees.append(DecisionTree().grow(df, labels, max_tree_depth, min_split_samples))\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, row):\n",
    "        if not isinstance(row, pd.Series):\n",
    "            raise Exception(\"`row` must be an instance of Pandas.Series\")\n",
    "        \n",
    "        predictions = [tree.predict(row) for tree in self.trees]\n",
    "        return np.bincount(predictions).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft = train.iloc[:, 0:50]\n",
    "# rf = RandomForest()\n",
    "# rf.grow(dft, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_row = -5\n",
    "# rf.predict(train.iloc[test_row]), labels.iloc[test_row]\n",
    "# merge(dft, labels).groupby(\"label\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "# Model Training & Tuning\n",
    "## Context\n",
    "Now that we have our classifier, let's think about how we're going to train the model. \n",
    "\n",
    "We'll also measure performance through [precision](https://en.wikipedia.org/wiki/Precision_and_recall) & [recall](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c) - it tells us, for each class, how well the model identifies all cases of that class (recall) and how well it can correctly classify those cases (precision). From wikipedia:\n",
    "> Suppose a computer program for recognizing dogs in photographs identifies eight dogs in a picture containing 12 dogs and some cats. Of the eight dogs identified, five actually are dogs (true positives), while the rest are cats (false positives). The program's precision is 5/8 while its recall is 5/12.\n",
    "\n",
    "![precision & recall formulas](https://cdn-images-1.medium.com/max/2000/1*6NkN_LINs2erxgVJ9rkpUA.png)\n",
    "We can use the [f1 score](https://en.wikipedia.org/wiki/F1_score) to maximize precision and recall when testing different models.  \n",
    "![f1 score formula](https://cdn-images-1.medium.com/max/1600/1*UJxVqLnbSj42eRhasKeLOA.png)\n",
    "\n",
    "Recall and precision seem to be very related to bias and variance of the model, so we can maximize the f1 score by tuning the model to affect these.\n",
    "#### Minimizing bias\n",
    "- use new/different features\n",
    "- increase the size of the trees (increases variance)\n",
    "- increase the number of trees in the forest\n",
    "\n",
    "#### Minimizing variance\n",
    "- decrease the number of features\n",
    "    + probably want to aim to features that are correlated and/or collapse the overall number of features through PCA\n",
    "- use more data for each tree  \n",
    "\n",
    "  \n",
    "Beware: too much completixy is bad & not enough complexity is also bad  \n",
    "![bias variance tradeoff](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)  \n",
    "  \n",
    "\n",
    "#### Stability\n",
    "We need to make sure to train the classifier on as many data points as possible while also leaving enough to test to reliably tell how well the classifier actually performs. We'll use [k-fold cross validation](https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/):  \n",
    "  \n",
    "> 1. Randomly split your entire dataset into k ”folds”.\n",
    "2. For each k folds in your dataset, build your model on k – 1 folds of the data set. Then, test the model to check the effectiveness for kth fold.\n",
    "3. Record the error you see on each of the predictions.\n",
    "4. Repeat this until each of the k folds has served as the test set.\n",
    "\n",
    "## Procedure\n",
    "1. Record and save an input configuration for the random forest\n",
    "1. Separate data into k folds\n",
    "2. For each fold *k*: \n",
    "    1. train the classifier on k-1 folds\n",
    "    2. predict the k-th fold\n",
    "    3. measure the: accuracy, [logarithmic](http://wiki.fast.ai/index.php/Log_Loss) [loss](https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234#f217), recall, precision, and f1-score\n",
    "3. Record the performance measures & associate it with the input configuration\n",
    "3. Evaluate the overall performance difference across all configurations\n",
    "4. Change **at most** 1 variable from the input configuration that optimizes perfomance & repeat steps 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record and save input config\n",
    "expiriments = []\n",
    "expiriments.append([  \n",
    "    # num_trees, num_features, num_sample_rows, max_tree_depth, min_split_samples\n",
    "      10,        None,         None ,           20,              5 # default settings = initial settings\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folds(df, labels, k=10):\n",
    "    splitter = int(np.ceil(df.shape[0] / k))\n",
    "    df = shuffle(merge(df, labels))\n",
    "    labels = df.pop(\"label\")\n",
    "    \n",
    "    folds = []\n",
    "    for i in range(1, k):\n",
    "        train = df.iloc[(i-1) * splitter: i * splitter]\n",
    "        test = df.iloc[np.r_[0:(i-1) * splitter, i*splitter: df.shape[0]]]\n",
    "        folds.append((train, test))\n",
    "    \n",
    "    return folds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, l = k_folds(train, labels)\n",
    "# f[7][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(model, test_set):\n",
    "    test_labels = test_set.pop(\"label\")\n",
    "    predictions = test_set.apply(lambda row: model.predict(row))\n",
    "    mprint(predictions)\n",
    "    \n",
    "    precision, recall, fscore, support = score(test_labels, predictions) # idea: test score(y_test, predicted, average=\"weighted\")\n",
    "    \n",
    "    return {\n",
    "        \"log_loss\" : log_loss(test_set, predictions, normalize=True),\n",
    "        \"class_accuracy\": accuracy_score(test_set, predictions, normalize=True),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"fscore\": fscore\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_train(df, labels, config, k=10):\n",
    "    performance_results = []\n",
    "    folds, labels = k_folds(df, labels, k)\n",
    "    \n",
    "    for i, test_train in enumerate(folds):\n",
    "        print(\" \")\n",
    "        print(\"*************************\")\n",
    "        print(\"Running {} of {} folds\".format(i+1, k))\n",
    "        print(\"*************************\")\n",
    "        print(\" \")\n",
    "        \n",
    "        rfc = RandomForest()\n",
    "        rfc.grow(test_train[1], pd.DataFrame(labels), *config)\n",
    "        performance_results.append(measure_performance(rfc, merge(test_train[0], pd.DataFrame(labels))))\n",
    "        \n",
    "    return performance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_train(train, labels, expiriments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Creating tree #1 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "classified f642 at depth 1 to be in class 1\n",
      "\n",
      "*** Creating tree #2 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "classified f62 at depth 1 to be in class 1\n",
      "\n",
      "*** Creating tree #3 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "classified f554 at depth 1 to be in class 1\n",
      "\n",
      "*** Creating tree #4 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "classified f566 at depth 1 to be in class 1\n",
      "\n",
      "*** Creating tree #5 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "parsing @ depth 2\n",
      "classified f176 at depth 2 to be in class 4\n",
      "parsing @ depth 2\n",
      "classified f173 at depth 2 to be in class 1\n",
      "Done with depth 1\n",
      "\n",
      "*** Creating tree #6 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "classified f84 at depth 1 to be in class 1\n",
      "\n",
      "*** Creating tree #7 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "parsing @ depth 2\n",
      "classified f662 at depth 2 to be in class 4\n",
      "parsing @ depth 2\n",
      "classified f683 at depth 2 to be in class 1\n",
      "Done with depth 1\n",
      "\n",
      "*** Creating tree #8 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "classified f155 at depth 1 to be in class 1\n",
      "\n",
      "*** Creating tree #9 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "classified f173 at depth 1 to be in class 1\n",
      "\n",
      "*** Creating tree #10 ***\n",
      "\n",
      "parsing @ depth 1\n",
      "classified f34 at depth 1 to be in class 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.RandomForest at 0x116857940>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, l = k_folds(train, labels)\n",
    "y_test, y_train = f[0]\n",
    "rfc = RandomForest()\n",
    "rfc.grow(y_train, pd.DataFrame(labels), *expiriments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = measure_performance(rfc, merge(y_test, pd.DataFrame(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
