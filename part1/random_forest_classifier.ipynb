{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%store -r\n",
    "from time import time\n",
    "from math import sqrt, floor\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from time import time\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import pandas as pd\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "from IPython.core.debugger import set_trace\n",
    "import pickle\n",
    "import os\n",
    "from rfc import RandomForest\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"cleaned_testData1.csv\")\n",
    "labels = pd.read_csv(\"cleaned_trainLabel1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train.columns[0], axis=1)\n",
    "labels = labels.drop(labels.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"model.binary\"\n",
    "train_file = \"model-train.csv\"\n",
    "test_file = \"model-test.csv\"\n",
    "\n",
    "def save_model(model, train_set, test_set):\n",
    "    with open(model_file, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    train_set.to_csv(train_file)\n",
    "    test_set.to_csv(test_file)\n",
    "\n",
    "def read_model():\n",
    "    if os.path.exists(\"model.binary\"):\n",
    "        with open(\"model.binary\", \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "        \n",
    "        return pd.read_csv(train_file), pd.read_csv(test_file), model\n",
    "    else:\n",
    "        False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df, labels):\n",
    "    return labels.merge(df, left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mprint(*args):\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "# Model Building\n",
    "\n",
    "## Which algorithm to use?\n",
    "We'll use a **random forest classifier** (rfc) with bootstrapping and feature bagging optimizations because:\n",
    "- ease of implementation\n",
    "- rfcs handle multi-class predictions well without more additional effort\n",
    "- works well with high dimensional data\n",
    "- we'll choose use random forest as opposed to boosted trees since we have highly dimensional data\n",
    "- with a reasonably high probability, can be used with the other datasets for this project since the algorithm is very robust\n",
    "\n",
    "## The Algorithm\n",
    "We'll use the CART algorithm for splitting since we have continuous data.  \n",
    "  \n",
    "[Full example](https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/)  \n",
    "  \n",
    "Steps:\n",
    "1. Initialize Tree\n",
    "2. For each column, calc best split across all rows based using gini impurity score - [exmplanation](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) | [exmaple](https://www.researchgate.net/post/How_to_compute_impurity_using_Gini_Index) | [useful blog](http://dni-institute.in/blogs/cart-algorithm-for-decision-tree/)\n",
    "3. Split the dataset based on the split condition with the highest gini score and add both sets as leaves on a tree node. The node represents a decision point, that being the condition with the highest gini score.\n",
    "3. Repeat 2 & 3 until an arbitrary minimum number of rows are left\n",
    "4. Prune tree\n",
    "\n",
    "ideas:\n",
    "- instead of using the raw values, categorize the numbers as # of stds away from mean\n",
    "- > Alternatively, the random forest can apply weight concept for considering the impact of result from any decision tree. Tree with high error rate are given low weight value and vise versa. This would increase the decision impact of trees with low error rate - [medium post](https://medium.com/machine-learning-101/chapter-5-random-forest-classifier-56dc7425c3e1)\n",
    "- [parameters to  tune](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n",
    "- https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "- https://stats.stackexchange.com/questions/260460/optimization-of-a-random-forest-model\n",
    "- https://followthedata.wordpress.com/2012/06/02/practical-advice-for-machine-learning-bias-variance/\n",
    "- https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "# Model Training & Tuning\n",
    "## Context\n",
    "Now that we have our classifier, let's think about how we're going to train the model. \n",
    "\n",
    "We'll also measure performance through [precision](https://en.wikipedia.org/wiki/Precision_and_recall) & [recall](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c) - it tells us, for each class, how well the model identifies all cases of that class (recall) and how well it can correctly classify those cases (precision). From wikipedia:\n",
    "> Suppose a computer program for recognizing dogs in photographs identifies eight dogs in a picture containing 12 dogs and some cats. Of the eight dogs identified, five actually are dogs (true positives), while the rest are cats (false positives). The program's precision is 5/8 while its recall is 5/12.\n",
    "\n",
    "![precision & recall formulas](https://cdn-images-1.medium.com/max/2000/1*6NkN_LINs2erxgVJ9rkpUA.png)\n",
    "We can use the [f1 score](https://en.wikipedia.org/wiki/F1_score) to maximize precision and recall when testing different models.  \n",
    "![f1 score formula](https://cdn-images-1.medium.com/max/1600/1*UJxVqLnbSj42eRhasKeLOA.png)\n",
    "\n",
    "Recall and precision seem to be very related to bias and variance of the model, so we can maximize the f1 score by tuning the model to affect these.\n",
    "#### Minimizing bias\n",
    "- use new/different features\n",
    "- increase the size of the trees (increases variance)\n",
    "- increase the number of trees in the forest\n",
    "\n",
    "#### Minimizing variance\n",
    "- decrease the number of features\n",
    "    + probably want to aim to features that are correlated and/or collapse the overall number of features through PCA\n",
    "- use more data for each tree  \n",
    "\n",
    "  \n",
    "Beware: too much completixy is bad & not enough complexity is also bad  \n",
    "![bias variance tradeoff](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)  \n",
    "  \n",
    "\n",
    "#### Stability\n",
    "We need to make sure to train the classifier on as many data points as possible while also leaving enough to test to reliably tell how well the classifier actually performs. We'll use [k-fold cross validation](https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/):  \n",
    "  \n",
    "> 1. Randomly split your entire dataset into k ”folds”.\n",
    "2. For each k folds in your dataset, build your model on k – 1 folds of the data set. Then, test the model to check the effectiveness for kth fold.\n",
    "3. Record the error you see on each of the predictions.\n",
    "4. Repeat this until each of the k folds has served as the test set.\n",
    "\n",
    "## Procedure\n",
    "1. Record and save an input configuration for the random forest\n",
    "1. Separate data into k folds\n",
    "2. For each fold *k*: \n",
    "    1. train the classifier on k-1 folds\n",
    "    2. predict the k-th fold\n",
    "    3. measure the: accuracy, [logarithmic](http://wiki.fast.ai/index.php/Log_Loss) [loss](https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234#f217), recall, precision, and f1-score\n",
    "3. Record the performance measures & associate it with the input configuration\n",
    "3. Evaluate the overall performance difference across all configurations\n",
    "4. Change **at most** 1 variable from the input configuration that optimizes perfomance & repeat steps 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, df, labels, model_class, model_config_names, model_config_init_values, k_folds=10):        \n",
    "        self.data = df\n",
    "        self.labels = labels\n",
    "        self.label_values = labels[\"label\"].unique()\n",
    "        self.model_class = model_class\n",
    "        self.model_config_names = model_config_names\n",
    "        \n",
    "        self.init_experiments(model_config_names, model_config_init_values)\n",
    "        \n",
    "        self.k_folds = k_folds\n",
    "    \n",
    "    def tweak(self, parameter, new_value):\n",
    "        self.current_experiment()[parameter] = new_value\n",
    "        return self\n",
    "    \n",
    "    def run_trial(self):\n",
    "        exp_num = self.experiments.shape[0]\n",
    "        mprint(\"Running trail #{}\\n------------------------------------\".format(exp_num))\n",
    "\n",
    "        performance_results = []\n",
    "        folds, labels = self.split_k_folds()\n",
    "        \n",
    "        config = self.current_model_config()\n",
    "        labels = pd.DataFrame(labels)\n",
    "        \n",
    "        for i, test_train in enumerate(folds):\n",
    "            mprint(\n",
    "                \"*************************\",\n",
    "                \"Running fold {} of {}\".format(i+1, self.k_folds),\n",
    "                \"*************************\"\n",
    "            )\n",
    "            \n",
    "            model = self.model()\n",
    "            t1 = time()\n",
    "            model.train(test_train[1], pd.DataFrame(labels), *config)\n",
    "            mprint(\"fold {} took {}s\".format(i+1, time() - t1))\n",
    "            performance = self.measure_performance(model, merge(test_train[0], labels), self.label_values)\n",
    "            \n",
    "            self.record_trial(i+1, performance, test_train[1], test_train[0], i+1 == len(folds))\n",
    "        \n",
    "        return self.trial_results\n",
    "        \n",
    "    def trial_results(self, trial_num=None):\n",
    "        if trial_num == None:\n",
    "            trial_num = self.experiments[\"trial_num\"].max() - 1\n",
    "        \n",
    "        return self.experiments[self.experiments[\"trial_num\"] == trial_num], self.experiment_data[int(trial_num)]    \n",
    "\n",
    "#<--------  PRIVATE METHODS -------->\n",
    "    def current_experiment(self):\n",
    "        return self.experiments[self.experiments[\"trial_num\"] == self.experiments[\"trial_num\"].max()]\n",
    "    \n",
    "    def current_model_config(self):\n",
    "        return self.current_experiment()[self.model_config_names].astype(\"int32\").values[0]\n",
    "        \n",
    "    def prev_experiment(self):\n",
    "        return self.experiments[self.experiments[\"trial_num\"] == (self.experiments[\"trial_num\"].max() - 1)]\n",
    "    \n",
    "    def trial_data(self, trial_num=None):\n",
    "        if trial_num == None:\n",
    "            trial_num = self.experiments[\"trial_num\"].max()-1\n",
    "        \n",
    "        return this.experiment_data[trial_num]\n",
    "    \n",
    "    def model(self):\n",
    "        return self.model_class(verbose=False)\n",
    "    \n",
    "    def init_experiments(self, config_names, config_values):\n",
    "        derived_cols = self.performance_measures() + [\"trial_num\"]\n",
    "        all_cols = config_names + derived_cols\n",
    "        first_row = config_values + [np.nan for i in derived_cols]\n",
    "        \n",
    "        self.experiments = pd.DataFrame(columns=all_cols)\n",
    "        self.experiments.loc[0] = first_row\n",
    "        self.experiments.loc[0][\"trial_num\"] = 1\n",
    "        self.experiments[config_names] = self.experiments[config_names].fillna(-1)\n",
    "        self.experiment_data = []\n",
    "    \n",
    "    def record_trial(self, trial_num, results, train, test, final=False):\n",
    "        for key in results:\n",
    "            self.current_experiment()[key] = results[key]\n",
    "        \n",
    "        if not final:\n",
    "            self.experiments.append(self.current_experiment())\n",
    "            self.experiment_data.append((train, test))\n",
    "            self.current_experiment()[\"trial_num\"] = trial_num + 1\n",
    "            \n",
    "    def performance_measures(self):\n",
    "        return [\"log_loss\", \"class_accuracy\", \"precision\", \"recall\", \"fscore\"]\n",
    "    \n",
    "    def split_k_folds(self):\n",
    "        splitter = int(np.ceil(self.data.shape[0] / self.k_folds))\n",
    "        df = shuffle(merge(self.data, self.labels))\n",
    "        labels = df.pop(\"label\")\n",
    "\n",
    "        folds = []\n",
    "        for i in range(1, self.k_folds+1):\n",
    "            train = df.iloc[(i-1) * splitter: i * splitter]\n",
    "            test = df.iloc[np.r_[0:(i-1) * splitter, i*splitter: df.shape[0]]]\n",
    "            folds.append((train, test))\n",
    "\n",
    "        return folds, labels\n",
    "    \n",
    "    def measure_performance(self, model, test_set, label_values=None):\n",
    "        test_labels = test_set.pop(\"label\")\n",
    "        if label_values is None:\n",
    "            label_values = test_labels.unique()\n",
    "\n",
    "        predictions = test_set.apply(lambda row: model.predict(row), axis=1)\n",
    "        precision, recall, fscore, support = score(test_labels, predictions, average='weighted')\n",
    "\n",
    "        lvs = [[1 if p == 1 else 0 for l in label_values] for p in predictions]\n",
    "        return {\n",
    "            \"log_loss\" : log_loss(test_labels, lvs, normalize=True, labels=label_values),\n",
    "            \"class_accuracy\": accuracy_score(test_labels, predictions, normalize=True),\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1-score\": fscore\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_config_names = [\"num_trees\", \"num_features\", \"num_sample_rows\", \"max_tree_depth\", \"min_split_samples\"]\n",
    "init_config_values = [   10,          None,           None,              20,                5] # default settings = initial settings\n",
    "\n",
    "e = Experiment(train, labels, RandomForest, init_config_names, init_config_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.run_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf, train_test = e.trial_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1 Notes:\n",
    "\n",
    "These settings were default. Since we have 5 features, the range of log loss is between 0 and 1.6, meaning our log loss is pretty bad. The accuracy looks good, but that's just because class 1 has a higher chance to appear in general. As we see in iteration 3, accuracy and recall are both _.267_. That iteration probably had more diverse labels than usual, but the model only got it right $\\frac{1}{5}^{th}%$ of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_trees</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_sample_rows</th>\n",
       "      <th>max_tree_depth</th>\n",
       "      <th>min_split_samples</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>class_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>trial_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.733</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.733</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.667</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.600</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.667</td>\n",
       "      <td>nan</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.733</td>\n",
       "      <td>nan</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.600</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.867</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.800</td>\n",
       "      <td>nan</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.786</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_trees  num_features  num_sample_rows  max_tree_depth  \\\n",
       "0     10.000        -1.000           -1.000          20.000   \n",
       "1     10.000        -1.000           -1.000          20.000   \n",
       "2     10.000        -1.000           -1.000          20.000   \n",
       "3     10.000        -1.000           -1.000          20.000   \n",
       "4     10.000        -1.000           -1.000          20.000   \n",
       "5     10.000        -1.000           -1.000          20.000   \n",
       "6     10.000        -1.000           -1.000          20.000   \n",
       "7     10.000        -1.000           -1.000          20.000   \n",
       "8     10.000        -1.000           -1.000          20.000   \n",
       "9     10.000        -1.000           -1.000          20.000   \n",
       "\n",
       "   min_split_samples  log_loss  class_accuracy  precision  recall  fscore  \\\n",
       "0              5.000     1.609           0.733      0.538   0.733     nan   \n",
       "1              5.000     1.609           0.733      0.538   0.733     nan   \n",
       "2              5.000     1.609           0.667      0.444   0.667     nan   \n",
       "3              5.000     1.609           0.600      0.360   0.600     nan   \n",
       "4              5.000     1.609           0.667      0.444   0.667     nan   \n",
       "5              5.000     1.609           0.733      0.538   0.733     nan   \n",
       "6              5.000     1.609           0.600      0.360   0.600     nan   \n",
       "7              5.000     1.609           0.867      0.751   0.867     nan   \n",
       "8              5.000     1.609           0.800      0.640   0.800     nan   \n",
       "9              5.000     1.609           0.786      0.617   0.786     nan   \n",
       "\n",
       "   trial_num  \n",
       "0      1.000  \n",
       "1      2.000  \n",
       "2      3.000  \n",
       "3      4.000  \n",
       "4      5.000  \n",
       "5      6.000  \n",
       "6      7.000  \n",
       "7      8.000  \n",
       "8      9.000  \n",
       "9     10.000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
