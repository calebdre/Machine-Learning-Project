{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to restore variable 'e', ignoring (use %store -d to forget!)\n",
      "The error was: <class 'KeyError'>\n",
      "Unable to restore variable 'e14', ignoring (use %store -d to forget!)\n",
      "The error was: <class 'KeyError'>\n",
      "Unable to restore variable 'e15', ignoring (use %store -d to forget!)\n",
      "The error was: <class 'KeyError'>\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%store -r\n",
    "\n",
    "from time import time\n",
    "\n",
    "from math import sqrt, floor\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use = \"default\"\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from rfc import RandomForest\n",
    "from Experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"cleaned_testData1.csv\")\n",
    "labels = pd.read_csv(\"cleaned_trainLabel1.csv\")\n",
    "test = pd.read_csv(\"TestData1.txt\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train.columns[0], axis=1)\n",
    "labels = labels.drop(labels.columns[0], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f151</th>\n",
       "      <th>f152</th>\n",
       "      <th>f153</th>\n",
       "      <th>f154</th>\n",
       "      <th>f155</th>\n",
       "      <th>f156</th>\n",
       "      <th>f157</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>...</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "      <td>149.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.513</td>\n",
       "      <td>1.204</td>\n",
       "      <td>1.262</td>\n",
       "      <td>1.888</td>\n",
       "      <td>1.390</td>\n",
       "      <td>1.668</td>\n",
       "      <td>1.305</td>\n",
       "      <td>1.743</td>\n",
       "      <td>2.567</td>\n",
       "      <td>1.913</td>\n",
       "      <td>...</td>\n",
       "      <td>1.562</td>\n",
       "      <td>2.009</td>\n",
       "      <td>1.751</td>\n",
       "      <td>2.210</td>\n",
       "      <td>2.285</td>\n",
       "      <td>2.707</td>\n",
       "      <td>2.787</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.920</td>\n",
       "      <td>2.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.410</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.257</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.349</td>\n",
       "      <td>1.343</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.651</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.894</td>\n",
       "      <td>1.829</td>\n",
       "      <td>2.389</td>\n",
       "      <td>2.391</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.483</td>\n",
       "      <td>2.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.231</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.676</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.315</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.586</td>\n",
       "      <td>2.493</td>\n",
       "      <td>1.793</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031</td>\n",
       "      <td>1.897</td>\n",
       "      <td>1.583</td>\n",
       "      <td>2.114</td>\n",
       "      <td>2.154</td>\n",
       "      <td>2.599</td>\n",
       "      <td>2.678</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.758</td>\n",
       "      <td>2.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.839</td>\n",
       "      <td>1.252</td>\n",
       "      <td>1.652</td>\n",
       "      <td>1.198</td>\n",
       "      <td>1.727</td>\n",
       "      <td>2.549</td>\n",
       "      <td>1.896</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597</td>\n",
       "      <td>2.005</td>\n",
       "      <td>1.723</td>\n",
       "      <td>2.197</td>\n",
       "      <td>2.262</td>\n",
       "      <td>2.707</td>\n",
       "      <td>2.785</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.863</td>\n",
       "      <td>2.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.659</td>\n",
       "      <td>1.204</td>\n",
       "      <td>1.361</td>\n",
       "      <td>2.026</td>\n",
       "      <td>1.570</td>\n",
       "      <td>1.842</td>\n",
       "      <td>1.455</td>\n",
       "      <td>1.853</td>\n",
       "      <td>2.609</td>\n",
       "      <td>1.996</td>\n",
       "      <td>...</td>\n",
       "      <td>1.872</td>\n",
       "      <td>2.103</td>\n",
       "      <td>1.866</td>\n",
       "      <td>2.283</td>\n",
       "      <td>2.386</td>\n",
       "      <td>2.798</td>\n",
       "      <td>2.897</td>\n",
       "      <td>1.327</td>\n",
       "      <td>1.955</td>\n",
       "      <td>2.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.027</td>\n",
       "      <td>2.713</td>\n",
       "      <td>2.862</td>\n",
       "      <td>2.984</td>\n",
       "      <td>2.754</td>\n",
       "      <td>3.507</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.760</td>\n",
       "      <td>2.986</td>\n",
       "      <td>2.573</td>\n",
       "      <td>...</td>\n",
       "      <td>2.658</td>\n",
       "      <td>2.861</td>\n",
       "      <td>2.856</td>\n",
       "      <td>2.579</td>\n",
       "      <td>2.945</td>\n",
       "      <td>3.285</td>\n",
       "      <td>3.274</td>\n",
       "      <td>2.728</td>\n",
       "      <td>3.050</td>\n",
       "      <td>3.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0      f1      f2      f3      f4      f5      f6      f7      f8  \\\n",
       "count 149.000 149.000 149.000 149.000 149.000 149.000 149.000 149.000 149.000   \n",
       "mean    1.513   1.204   1.262   1.888   1.390   1.668   1.305   1.743   2.567   \n",
       "std     0.410   0.404   0.437   0.342   0.460   0.560   0.370   0.333   0.119   \n",
       "min     1.000   1.000   1.000   1.257   1.000   1.000   1.000   1.000   2.349   \n",
       "25%     1.231   1.000   1.000   1.676   1.000   1.315   1.000   1.586   2.493   \n",
       "50%     1.475   1.000   1.000   1.839   1.252   1.652   1.198   1.727   2.549   \n",
       "75%     1.659   1.204   1.361   2.026   1.570   1.842   1.455   1.853   2.609   \n",
       "max     3.027   2.713   2.862   2.984   2.754   3.507   2.306   2.760   2.986   \n",
       "\n",
       "           f9   ...      f151    f152    f153    f154    f155    f156    f157  \\\n",
       "count 149.000   ...   149.000 149.000 149.000 149.000 149.000 149.000 149.000   \n",
       "mean    1.913   ...     1.562   2.009   1.751   2.210   2.285   2.707   2.787   \n",
       "std     0.209   ...     0.446   0.163   0.298   0.124   0.199   0.142   0.171   \n",
       "min     1.343   ...     1.000   1.651   1.000   1.894   1.829   2.389   2.391   \n",
       "25%     1.793   ...     1.031   1.897   1.583   2.114   2.154   2.599   2.678   \n",
       "50%     1.896   ...     1.597   2.005   1.723   2.197   2.262   2.707   2.785   \n",
       "75%     1.996   ...     1.872   2.103   1.866   2.283   2.386   2.798   2.897   \n",
       "max     2.573   ...     2.658   2.861   2.856   2.579   2.945   3.285   3.274   \n",
       "\n",
       "         f158    f159    f160  \n",
       "count 149.000 149.000 149.000  \n",
       "mean    1.225   1.920   2.801  \n",
       "std     0.369   0.294   0.134  \n",
       "min     1.000   1.483   2.493  \n",
       "25%     1.000   1.758   2.727  \n",
       "50%     1.000   1.863   2.780  \n",
       "75%     1.327   1.955   2.847  \n",
       "max     2.728   3.050   3.263  \n",
       "\n",
       "[8 rows x 161 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df, labels):\n",
    "    return labels.merge(df, left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mprint(*args):\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">f0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f98</th>\n",
       "      <th colspan=\"8\" halign=\"left\">f99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.000</td>\n",
       "      <td>1.444</td>\n",
       "      <td>0.285</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.247</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.614</td>\n",
       "      <td>2.378</td>\n",
       "      <td>107.000</td>\n",
       "      <td>1.099</td>\n",
       "      <td>...</td>\n",
       "      <td>2.425</td>\n",
       "      <td>2.565</td>\n",
       "      <td>107.000</td>\n",
       "      <td>2.622</td>\n",
       "      <td>0.102</td>\n",
       "      <td>2.388</td>\n",
       "      <td>2.549</td>\n",
       "      <td>2.625</td>\n",
       "      <td>2.693</td>\n",
       "      <td>2.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.000</td>\n",
       "      <td>1.190</td>\n",
       "      <td>0.235</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.051</td>\n",
       "      <td>1.370</td>\n",
       "      <td>1.630</td>\n",
       "      <td>14.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.487</td>\n",
       "      <td>2.521</td>\n",
       "      <td>14.000</td>\n",
       "      <td>2.586</td>\n",
       "      <td>0.087</td>\n",
       "      <td>2.431</td>\n",
       "      <td>2.530</td>\n",
       "      <td>2.581</td>\n",
       "      <td>2.615</td>\n",
       "      <td>2.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.000</td>\n",
       "      <td>1.320</td>\n",
       "      <td>0.245</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.175</td>\n",
       "      <td>1.294</td>\n",
       "      <td>1.438</td>\n",
       "      <td>1.837</td>\n",
       "      <td>11.000</td>\n",
       "      <td>1.019</td>\n",
       "      <td>...</td>\n",
       "      <td>2.458</td>\n",
       "      <td>2.541</td>\n",
       "      <td>11.000</td>\n",
       "      <td>2.785</td>\n",
       "      <td>0.057</td>\n",
       "      <td>2.661</td>\n",
       "      <td>2.762</td>\n",
       "      <td>2.788</td>\n",
       "      <td>2.804</td>\n",
       "      <td>2.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.000</td>\n",
       "      <td>2.352</td>\n",
       "      <td>0.248</td>\n",
       "      <td>2.081</td>\n",
       "      <td>2.167</td>\n",
       "      <td>2.300</td>\n",
       "      <td>2.451</td>\n",
       "      <td>3.027</td>\n",
       "      <td>14.000</td>\n",
       "      <td>2.277</td>\n",
       "      <td>...</td>\n",
       "      <td>2.657</td>\n",
       "      <td>2.799</td>\n",
       "      <td>14.000</td>\n",
       "      <td>2.869</td>\n",
       "      <td>0.146</td>\n",
       "      <td>2.655</td>\n",
       "      <td>2.766</td>\n",
       "      <td>2.864</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.327</td>\n",
       "      <td>1.883</td>\n",
       "      <td>2.120</td>\n",
       "      <td>2.357</td>\n",
       "      <td>2.434</td>\n",
       "      <td>2.512</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.590</td>\n",
       "      <td>...</td>\n",
       "      <td>2.542</td>\n",
       "      <td>2.576</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.713</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2.629</td>\n",
       "      <td>2.664</td>\n",
       "      <td>2.699</td>\n",
       "      <td>2.755</td>\n",
       "      <td>2.810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0                                                f1        ...   \\\n",
       "        count  mean   std   min   25%   50%   75%   max   count  mean  ...    \n",
       "label                                                                  ...    \n",
       "1     107.000 1.444 0.285 1.000 1.247 1.465 1.614 2.378 107.000 1.099  ...    \n",
       "2      14.000 1.190 0.235 1.000 1.000 1.051 1.370 1.630  14.000 1.000  ...    \n",
       "3      11.000 1.320 0.245 1.000 1.175 1.294 1.438 1.837  11.000 1.019  ...    \n",
       "4      14.000 2.352 0.248 2.081 2.167 2.300 2.451 3.027  14.000 2.277  ...    \n",
       "5       3.000 2.250 0.327 1.883 2.120 2.357 2.434 2.512   3.000 1.590  ...    \n",
       "\n",
       "        f98           f99                                            \n",
       "        75%   max   count  mean   std   min   25%   50%   75%   max  \n",
       "label                                                                \n",
       "1     2.425 2.565 107.000 2.622 0.102 2.388 2.549 2.625 2.693 2.883  \n",
       "2     2.487 2.521  14.000 2.586 0.087 2.431 2.530 2.581 2.615 2.796  \n",
       "3     2.458 2.541  11.000 2.785 0.057 2.661 2.762 2.788 2.804 2.871  \n",
       "4     2.657 2.799  14.000 2.869 0.146 2.655 2.766 2.864 2.936 3.125  \n",
       "5     2.542 2.576   3.000 2.713 0.091 2.629 2.664 2.699 2.755 2.810  \n",
       "\n",
       "[5 rows x 1288 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge(train, labels).groupby(\"label\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "# Model Building\n",
    "\n",
    "## Which algorithm to use?\n",
    "We'll use a **random forest classifier** (rfc) with bootstrapping and feature bagging optimizations because:\n",
    "- ease of implementation\n",
    "- rfcs handle multi-class predictions well without more additional effort\n",
    "- works well with high dimensional data\n",
    "- we'll choose use random forest as opposed to boosted trees since we have highly dimensional data\n",
    "- with a reasonably high probability, can be used with the other datasets for this project since the algorithm is very robust\n",
    "\n",
    "## The Algorithm\n",
    "We'll use the CART algorithm for splitting since we have continuous data.  \n",
    "  \n",
    "[Full example](https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/)  \n",
    "  \n",
    "Steps:\n",
    "1. Initialize Tree\n",
    "2. For each column, calc best split across all rows based using gini impurity score - [exmplanation](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) | [exmaple](https://www.researchgate.net/post/How_to_compute_impurity_using_Gini_Index) | [useful blog](http://dni-institute.in/blogs/cart-algorithm-for-decision-tree/)\n",
    "3. Split the dataset based on the split condition with the highest gini score and add both sets as leaves on a tree node. The node represents a decision point, that being the condition with the highest gini score.\n",
    "3. Repeat 2 & 3 until an arbitrary minimum number of rows are left\n",
    "4. Prune tree\n",
    "\n",
    "ideas:\n",
    "- instead of using the raw values, categorize the numbers as # of stds away from mean\n",
    "- > Alternatively, the random forest can apply weight concept for considering the impact of result from any decision tree. Tree with high error rate are given low weight value and vise versa. This would increase the decision impact of trees with low error rate - [medium post](https://medium.com/machine-learning-101/chapter-5-random-forest-classifier-56dc7425c3e1)\n",
    "- [parameters to  tune](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n",
    "- https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "- https://stats.stackexchange.com/questions/260460/optimization-of-a-random-forest-model\n",
    "- https://followthedata.wordpress.com/2012/06/02/practical-advice-for-machine-learning-bias-variance/\n",
    "- https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "# Model Training & Tuning\n",
    "## Context\n",
    "Now that we have our classifier, let's think about how we're going to train the model. \n",
    "\n",
    "We'll also measure performance through [precision](https://en.wikipedia.org/wiki/Precision_and_recall) & [recall](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c) - it tells us, for each class, how well the model identifies all cases of that class (recall) and how well it can correctly classify those cases (precision). From wikipedia:\n",
    "> Suppose a computer program for recognizing dogs in photographs identifies eight dogs in a picture containing 12 dogs and some cats. Of the eight dogs identified, five actually are dogs (true positives), while the rest are cats (false positives). The program's precision is 5/8 while its recall is 5/12.\n",
    "\n",
    "![precision & recall formulas](https://cdn-images-1.medium.com/max/2000/1*6NkN_LINs2erxgVJ9rkpUA.png)\n",
    "We can use the [f1 score](https://en.wikipedia.org/wiki/F1_score) to maximize precision and recall when testing different models.  \n",
    "![f1 score formula](https://cdn-images-1.medium.com/max/1600/1*UJxVqLnbSj42eRhasKeLOA.png)\n",
    "\n",
    "Recall and precision seem to be very related to bias and variance of the model, so we can maximize the f1 score by tuning the model to affect these.\n",
    "#### Minimizing bias\n",
    "- use new/different features\n",
    "- increase the size of the trees (increases variance)\n",
    "- increase the number of trees in the forest\n",
    "\n",
    "#### Minimizing variance\n",
    "- decrease the number of features\n",
    "    + probably want to aim to features that are correlated and/or collapse the overall number of features through PCA\n",
    "- use more data for each tree  \n",
    "\n",
    "  \n",
    "Beware: too much completixy is bad & not enough complexity is also bad  \n",
    "![bias variance tradeoff](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)  \n",
    "  \n",
    "\n",
    "#### Stability\n",
    "We need to make sure to train the classifier on as many data points as possible while also leaving enough to test to reliably tell how well the classifier actually performs. We'll use [k-fold cross validation](https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/):  \n",
    "  \n",
    "> 1. Randomly split your entire dataset into k ”folds”.\n",
    "2. For each k folds in your dataset, build your model on k – 1 folds of the data set. Then, test the model to check the effectiveness for kth fold.\n",
    "3. Record the error you see on each of the predictions.\n",
    "4. Repeat this until each of the k folds has served as the test set.\n",
    "\n",
    "## Procedure\n",
    "1. Record and save an input configuration for the random forest\n",
    "1. Separate data into k folds\n",
    "2. For each fold *k*: \n",
    "    1. train the classifier on k-1 folds\n",
    "    2. predict the k-th fold\n",
    "    3. measure the: accuracy, [logarithmic](http://wiki.fast.ai/index.php/Log_Loss) [loss](https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234#f217), recall, precision, and f1-score\n",
    "3. Record the performance measures & associate it with the input configuration\n",
    "3. Evaluate the overall performance difference across all configurations\n",
    "4. Change variables from the input configuration that optimizes model perfomance & repeat steps 1-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WOWZA](https://i.imgur.com/hzxSFl5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_config_names = [\"num_trees\", \"num_features\", \"num_sample_rows\", \"max_tree_depth\", \"min_split_samples\", \"bias_class\", \"bias_amount\"]\n",
    "init_config_values = [   10,          None,           None,              20,                5,                 None,            0] # default settings = initial settings\n",
    "\n",
    "e = Experiment(train, labels, RandomForest, init_config_names, init_config_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trail #1\n",
      "------------------------------------\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 1 of 10\n",
      " \n",
      "*************************\n",
      " \n",
      "fold 1 took 53.488991022109985s\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 2 of 10\n",
      " \n",
      "*************************\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 took 51.035489082336426s\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 3 of 10\n",
      " \n",
      "*************************\n",
      " \n",
      "fold 3 took 55.5192608833313s\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 4 of 10\n",
      " \n",
      "*************************\n",
      " \n",
      "fold 4 took 88.43484807014465s\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 5 of 10\n",
      " \n",
      "*************************\n",
      " \n",
      "fold 5 took 78.9311318397522s\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 6 of 10\n",
      " \n",
      "*************************\n",
      " \n",
      "fold 6 took 77.27893304824829s\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 7 of 10\n",
      " \n",
      "*************************\n",
      " \n",
      "fold 7 took 67.64726614952087s\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 8 of 10\n",
      " \n",
      "*************************\n",
      " \n",
      "fold 8 took 67.07492399215698s\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 9 of 10\n",
      " \n",
      "*************************\n",
      " \n",
      "fold 9 took 58.04343509674072s\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 10 of 10\n",
      " \n",
      "*************************\n",
      " \n",
      "fold 10 took 68.30269289016724s\n",
      " \n",
      "Stored 'e' (Experiment)\n"
     ]
    }
   ],
   "source": [
    "t1 = e.run_trial()\n",
    "%store e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf, train_test = e.trial_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1 Notes:\n",
    "\n",
    "These settings were default. Since we have 5 classes, the range of log loss is between 0 and 1.6, meaning our log loss is pretty bad and that we're very likely to misclassify. The accuracy seems good, but that's only because class 1 has a higher chance to appear in general as it appears ~70% of the time. As we see in iteration 7, accuracy and precision are _.533_ and _.284_  respectively. That iteration probably had more diverse labels than usual, but the model only got it right $\\frac{1}{4}^{th}%$ of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, t_7_train, t_7_test, t_7_predict  = e.experiment_data[6]\n",
    "\n",
    "t_7_train_g = merge(t_7_train[0], labels).groupby(\"label\")\n",
    "t_7_test_g = merge(t_7_test, labels).groupby(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10a385e48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1099e5128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e.experiments.sort_values([\"recall\", \"precision\"]).plot(\"recall\", \"precision\", \"line\", figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very odd that precision and recall move in step.. Not sure what that means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_loss         1.609\n",
       "class_accuracy   0.711\n",
       "precision        0.518\n",
       "recall           0.711\n",
       "f1-score         0.596\n",
       "support            nan\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.experiments[e.performance_measures()].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_means = merge(train, labels).groupby(\"label\").count().apply(lambda x: x / train.shape[0]).T.mean()\n",
    "\n",
    "# average bias\n",
    "# pd.DataFrame([i[2].value_counts(normalize=True) - expected_means for i in e.experiment_data]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it seems like the classifier is stuck on the imbalance of classes in the dataset. We have close to 0 variance but lots of bias. We can count the `nan`s above as $0 - class$.  \n",
    "\n",
    "To combat this, we'll add more & deeper trees in hopes that the model will pick up on more variance, train some trees only on data that have the imbalanced classes, and use less data to train the model with in order to reduce the extent to which a single class and dominate the others.  \n",
    "  \n",
    "We can also increase the number of samples that we give a tree to something that will mirror the overall statistical properties of the original set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1   0.783\n",
       "2   0.050\n",
       "3   0.050\n",
       "4   0.117\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this a few times to minimize s_rows and statistical difference in label means\n",
    "s_rows = 60\n",
    "row_indices = np.random.choice(train.shape[0], size=s_rows, replace=False)\n",
    "merge(train.iloc[row_indices], labels).groupby(\"label\").count().apply(lambda x: x / s_rows).T.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment.Experiment at 0x1099494e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tweak(\"num_trees\", 20).tweak(\"min_split_samples\", 1).tweak(\"num_sample_rows\", s_rows).tweak(\"num_features\", 20).tweak(\"bias_class\", 1).tweak(\"bias_amount\", .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trail #11\n",
      "------------------------------------\n",
      " \n",
      "*************************\n",
      " \n",
      "Running fold 1 of 10\n",
      " \n",
      "*************************\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-611:\n",
      "Process ForkPoolWorker-610:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d20c82923aca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trial_num\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'store'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/dataanalytics/ml-project/Experiment.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mmprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fold {} took {}s\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/dataanalytics/ml-project/rfc.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, origin_df, labels, num_trees, num_features, num_sample_rows, max_tree_depth, min_split_samples, bias_class, bias_amount)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*** Creating tree #{} ***\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tree_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_split_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtree_selections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/dataanalytics/ml-project/rfc.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, origin_df, labels, max_depth, min_split_samples)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_recurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/dataanalytics/ml-project/rfc.py\u001b[0m in \u001b[0;36mtrain_recurse\u001b[0;34m(df, labels, depth)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_recurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parsing @ depth {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_best_gini_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mleft_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mright_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/dataanalytics/ml-project/rfc.py\u001b[0m in \u001b[0;36mcalc_best_gini_split\u001b[0;34m(df, labels)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mmins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmins_best_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if e.experiments[e.experiments[\"trial_num\"] > 1].shape[0] < 2:\n",
    "    e.run_trial()\n",
    "    %store e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_results, t2_train_test =  e.trial_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.experiments\n",
    "e.experiment_data[9][2].to_csv(\"predictions.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_results.sort_values([\"recall\", \"precision\"]).plot(\"recall\", \"precision\", \"line\", figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 2 Notes:\n",
    "Welp - that didn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "`row` must be an instance of Pandas.Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-52d606c2e55b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions1.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/dataanalytics/ml-project/rfc.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`row` must be an instance of Pandas.Series\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: `row` must be an instance of Pandas.Series"
     ]
    }
   ],
   "source": [
    "r = e.experiment_data[0][0].predict(test)\n",
    "r.to_csv(\"predictions1.txt\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ORIGIN RUNTIME **  \n",
    "$ O(folds * trees * max_depth * row^{columns})  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PARALLELIZED RUNTIME **\n",
    "$ O(folds * trees * max_depth * row^{\\frac{columns}{threads}})  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
